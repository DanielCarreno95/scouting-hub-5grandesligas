# =====================================
# utils/data_loader.py  ‚úÖ VERSI√ìN LIMPIA (sin mensaje de carga)
# =====================================

import pandas as pd
import numpy as np
import streamlit as st
from pathlib import Path

# ==============================
# Funciones de carga de datos
# ==============================

@st.cache_data
def load_parquet_data(path: str):
    """Carga un archivo Parquet con cacheo para optimizar rendimiento."""
    return pd.read_parquet(path)

@st.cache_data
def load_csv_data(path: str):
    """Carga un archivo CSV con cacheo."""
    return pd.read_csv(path)

# ==============================
# Funciones auxiliares
# ==============================

def normalize_0_1(series: pd.Series):
    """Normaliza una serie num√©rica entre 0 y 1."""
    if series.max() == series.min():
        return np.zeros_like(series)
    return (series - series.min()) / (series.max() - series.min())

def build_row_key(df: pd.DataFrame, cols: list):
    """Crea una columna √∫nica de clave combinada."""
    return df[cols].astype(str).agg('_'.join, axis=1)

def get_latest_processed_file(folder="data/processed", prefix="scouting_laliga_df_final_", ext=".parquet"):
    """Encuentra autom√°ticamente el archivo procesado m√°s reciente."""
    p = Path(folder)
    archivos = sorted(p.glob(f"{prefix}*{ext}"), key=lambda x: x.stat().st_mtime, reverse=True)
    if not archivos:
        raise FileNotFoundError(f"No se encontr√≥ ning√∫n archivo con prefijo {prefix} en {folder}")
    return archivos[0]

# ==============================
# Funci√≥n principal de carga
# ==============================

@st.cache_data
def load_main_dataset():
    """
    Carga el dataset procesado m√°s reciente y lo prepara para uso en la app.
    - Detecta autom√°ticamente el √∫ltimo archivo exportado.
    - Convierte nombres de columnas a min√∫sculas.
    - Crea 'row_key' combinando player + season + squad.
    - Asegura columna 'league'.
    - Verifica rango 0‚Äì100 solo en m√©tricas escaladas.
    """
    # Buscar el archivo m√°s reciente generado por el ETL
    latest_file = get_latest_processed_file()
    # üßπ Se elimin√≥ el mensaje "Cargando dataset procesado m√°s reciente"

    # Leer el parquet
    df = load_parquet_data(str(latest_file))

    # Estandarizar nombres de columnas
    df.columns = [c.lower() for c in df.columns]

    # Crear columna clave √∫nica
    base_cols = [c for c in ["player", "season", "squad"] if c in df.columns]
    if len(base_cols) == 3:
        df["row_key"] = build_row_key(df, base_cols)
    else:
        st.warning("‚ö†Ô∏è No se pudieron crear las claves √∫nicas: faltan columnas base (player, season o squad).")

    # Renombrar 'comp' ‚Üí 'league' si existe
    if "comp" in df.columns:
        df.rename(columns={"comp": "league"}, inplace=True)
    elif "league" not in df.columns:
        df["league"] = "Desconocida"

    # ‚úÖ Validar solo m√©tricas escaladas (las *_per90 y los %)
    cols_check = [c for c in df.columns if c.endswith("_per90") or c.endswith("%")]
    if cols_check:
        fuera_de_rango = df[(df[cols_check] < 0).any(axis=1) | (df[cols_check] > 100).any(axis=1)]
        if not fuera_de_rango.empty:
            st.warning(f"‚ö†Ô∏è {len(fuera_de_rango)} filas tienen valores fuera del rango esperado (0‚Äì100) en m√©tricas escaladas.")

    return df
